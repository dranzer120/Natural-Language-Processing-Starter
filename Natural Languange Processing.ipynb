{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello students, how are you doing today?', 'The olympics are inspiring, and Python is awesome.', 'You look nice today.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "text = \"Hello students, how are you doing today? The olympics are inspiring, and Python is awesome. You look nice today.\"\n",
    "\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'students', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'olympics', 'are', 'inspiring', ',', 'and', 'Python', 'is', 'awesome', '.', 'You', 'look', 'nice', 'today', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you've\", 'out', 'will', 'it', 'himself', 'theirs', 'where', 'did', 'again', \"hadn't\", 'with', 'can', \"aren't\", 'yourselves', 've', 'have', 'ma', 'his', 'needn', 'under', 'off', 'when', 're', 'while', \"you'll\", 'their', \"mustn't\", 'this', \"wouldn't\", 'won', 'these', 'll', 'but', 'down', 'my', 'hasn', 's', 'they', 'ourselves', 'does', 'ain', 'hers', \"shouldn't\", \"mightn't\", 'until', 'at', 'ours', 'its', 'y', \"you'd\", 'a', 'wasn', 'me', 'those', \"she's\", 'here', 'too', 'haven', 'shan', \"hasn't\", 'him', 'above', 'yours', 'an', 'very', 'being', 'should', 'as', 'to', 'about', 'all', 'just', 'the', \"it's\", 'which', 'against', 'doesn', 'themselves', 'further', 'aren', 'there', 'into', 'were', 'and', 'weren', 'few', 'once', 'why', 'mustn', \"needn't\", 'i', 'that', 'isn', 'mightn', 'of', \"couldn't\", 'any', 'by', 'are', \"won't\", 'more', 'do', 'such', \"didn't\", 'what', 'our', 'doing', 'own', \"that'll\", 'now', \"weren't\", 'didn', \"shan't\", 'other', 'if', 'myself', 'wouldn', 'he', 't', 'below', 'am', 'how', 'm', 'after', 'her', 'during', 'only', 'not', 'than', \"wasn't\", 'been', 'your', 'some', \"you're\", 'so', 'for', \"doesn't\", 'shouldn', 'over', 'nor', 'having', 'you', 'we', 'd', \"don't\", 'each', \"isn't\", 'from', 'don', 'yourself', 'them', 'in', 'before', 'most', 'both', 'same', 'she', \"should've\", 'who', 'because', 'hadn', 'up', 'or', 'itself', 'between', 'no', 'through', 'o', 'whom', 'be', 'couldn', 'on', 'was', 'is', 'then', \"haven't\", 'herself', 'has', 'had'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'some', 'sample', 'text', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'text', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "example_sent = \"This is some sample text, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride\n",
      "ride\n",
      "rider\n",
      "ride\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "example_words = [\"ride\",\"riding\",\"rider\",\"rides\"]\n",
    "\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when\n",
      "rider\n",
      "are\n",
      "ride\n",
      "their\n",
      "hors\n",
      ",\n",
      "they\n",
      "often\n",
      "think\n",
      "of\n",
      "how\n",
      "cowboy\n",
      "rode\n",
      "hors\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Now lets try stemming an entire sentence!\n",
    "\n",
    "new_text = \"When riders are riding their horses, they often think of how cowboys rode horses.\"\n",
    "\n",
    "words = word_tokenize(new_text)\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal Declaration of Human Rights\n",
      "Preamble\n",
      "Whereas recognition of the inherent dignity and of the equal and inalienable rights of all members of the human family is the foundation of freedom, justice and peace in the world, \n",
      "\n",
      "Whereas disregard and contempt for human rights have resulted in barbarous acts which have outraged the conscience of mankind, and the advent of a world in which human beings shall enjoy freedom of speech and belief and freedom from fear and want has been proclaimed as the highest aspiration of the common people, \n",
      "\n",
      "Whereas it is essential, if man is not to be compelled to have recourse, as a last resort, to rebellion against tyranny and oppression, that human rights should be protected by the rule of law, \n",
      "\n",
      "Whereas it is essential to promote the development of friendly relations between nations, \n",
      "\n",
      "Whereas the peoples of the United Nations have in the Charter reaffirmed their faith in fundamental human rights, in the dignity and worth of the human person and in the equal rights of men and women and have determined to promote social progress and better standards of life in larger freedom, \n",
      "\n",
      "Whereas Member States have pledged themselves to achieve, in cooperation with the United Nations, the promotion of universal respect for and observance of human rights and fundamental freedoms, \n",
      "\n",
      "Whereas a common understanding of these rights and freedoms is of the greatest importance for the full realization of this pledge, \n",
      "\n",
      "Now, therefore, \n",
      "\n",
      "The General Assembly, \n",
      "\n",
      "Proclaims this Universal Declaration of Human Rights as a common standard of achievement for all peoples and all nations, to the end that every individual and every organ of society, keeping this Declaration constantly in mind, shall strive by teaching and education to promote respect for these rights and freedoms and by progressive measures, national and international, to secure their universal and effective recognition and observance, both among the peoples of Member States themselves and among the peoples of territories under their jurisdiction. \n",
      "\n",
      "Article 1 \n",
      "All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood. \n",
      "\n",
      "Article 2 \n",
      "Everyone is entitled to all the rights and freedoms set forth in this Declaration, without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status. \n",
      "\n",
      "Furthermore, no distinction shall be made on the basis of the political, jurisdictional or international status of the country or territory to which a person belongs, whether it be independent, trust, non-self-governing or under any other limitation of sovereignty. \n",
      "\n",
      "Article 3 \n",
      "Everyone has the right to life, liberty and security of person. \n",
      "\n",
      "Article 4 \n",
      "No one shall be held in slavery or servitude; slavery and the slave trade shall be prohibited in all their forms. \n",
      "\n",
      "Article 5 \n",
      "No one shall be subjected to torture or to cruel, inhuman or degrading treatment or punishment. \n",
      "\n",
      "Article 6 \n",
      "Everyone has the right to recognition everywhere as a person before the law. \n",
      "\n",
      "Article 7 \n",
      "All are equal before the law and are entitled without any discrimination to equal protection of the law. All are entitled to equal protection against any discrimination in violation of this Declaration and against any incitement to such discrimination. \n",
      "\n",
      "Article 8 \n",
      "Everyone has the right to an effective remedy by the competent national tribunals for acts violating the fundamental rights granted him by the constitution or by law. \n",
      "\n",
      "Article 9 \n",
      "No one shall be subjected to arbitrary arrest, detention or exile. \n",
      "\n",
      "Article 10 \n",
      "Everyone is entitled in full equality to a fair and public hearing by an independent and impartial tribunal, in the determination of his rights and obligations and of any criminal charge against him. \n",
      "\n",
      "Article 11 \n",
      "Everyone charged with a penal offence has the right to be presumed innocent until proved guilty according to law in a public trial at which he has had all the guarantees necessary for his defence. \n",
      "No one shall be held guilty of any penal offence on account of any act or omission which did not constitute a penal offence, under national or international law, at the time when it was committed. Nor shall a heavier penalty be imposed than the one that was applicable at the time the penal offence was committed. \n",
      "Article 12 \n",
      "No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence, nor to attacks upon his honour and reputation. Everyone has the right to the protection of the law against such interference or attacks. \n",
      "\n",
      "Article 13 \n",
      "Everyone has the right to freedom of movement and residence within the borders of each State. \n",
      "Everyone has the right to leave any country, including his own, and to return to his country. \n",
      "Article 14 \n",
      "Everyone has the right to seek and to enjoy in other countries asylum from persecution. \n",
      "This right may not be invoked in the case of prosecutions genuinely arising from non-political crimes or from acts contrary to the purposes and principles of the United Nations. \n",
      "Article 15 \n",
      "Everyone has the right to a nationality. \n",
      "No one shall be arbitrarily deprived of his nationality nor denied the right to change his nationality. \n",
      "Article 16 \n",
      "Men and women of full age, without any limitation due to race, nationality or religion, have the right to marry and to found a family. They are entitled to equal rights as to marriage, during marriage and at its dissolution. \n",
      "Marriage shall be entered into only with the free and full consent of the intending spouses. \n",
      "The family is the natural and fundamental group unit of society and is entitled to protection by society and the State. \n",
      "Article 17 \n",
      "Everyone has the right to own property alone as well as in association with others. \n",
      "No one shall be arbitrarily deprived of his property. \n",
      "Article 18 \n",
      "Everyone has the right to freedom of thought, conscience and religion; this right includes freedom to change his religion or belief, and freedom, either alone or in community with others and in public or private, to manifest his religion or belief in teaching, practice, worship and observance. \n",
      "\n",
      "Article 19 \n",
      "Everyone has the right to freedom of opinion and expression; this right includes freedom to hold opinions without interference and to seek, receive and impart information and ideas through any media and regardless of frontiers. \n",
      "\n",
      "Article 20 \n",
      "Everyone has the right to freedom of peaceful assembly and association. \n",
      "No one may be compelled to belong to an association. \n",
      "Article 21 \n",
      "Everyone has the right to take part in the government of his country, directly or through freely chosen representatives. \n",
      "Everyone has the right to equal access to public service in his country. \n",
      "The will of the people shall be the basis of the authority of government; this will shall be expressed in periodic and genuine elections which shall be by universal and equal suffrage and shall be held by secret vote or by equivalent free voting procedures. \n",
      "Article 22 \n",
      "Everyone, as a member of society, has the right to social security and is entitled to realization, through national effort and international co-operation and in accordance with the organization and resources of each State, of the economic, social and cultural rights indispensable for his dignity and the free development of his personality. \n",
      "\n",
      "Article 23 \n",
      "Everyone has the right to work, to free choice of employment, to just and favourable conditions of work and to protection against unemployment. \n",
      "Everyone, without any discrimination, has the right to equal pay for equal work. \n",
      "Everyone who works has the right to just and favourable remuneration ensuring for himself and his family an existence worthy of human dignity, and supplemented, if necessary, by other means of social protection. \n",
      "Everyone has the right to form and to join trade unions for the protection of his interests. \n",
      "Article 24 \n",
      "Everyone has the right to rest and leisure, including reasonable limitation of working hours and periodic holidays with pay. \n",
      "\n",
      "Article 25 \n",
      "Everyone has the right to a standard of living adequate for the health and well-being of himself and of his family, including food, clothing, housing and medical care and necessary social services, and the right to security in the event of unemployment, sickness, disability, widowhood, old age or other lack of livelihood in circumstances beyond his control. \n",
      "Motherhood and childhood are entitled to special care and assistance. All children, whether born in or out of wedlock, shall enjoy the same social protection. \n",
      "Article 26 \n",
      "Everyone has the right to education. Education shall be free, at least in the elementary and fundamental stages. Elementary education shall be compulsory. Technical and professional education shall be made generally available and higher education shall be equally accessible to all on the basis of merit. \n",
      "Education shall be directed to the full development of the human personality and to the strengthening of respect for human rights and fundamental freedoms. It shall promote understanding, tolerance and friendship among all nations, racial or religious groups, and shall further the activities of the United Nations for the maintenance of peace. \n",
      "Parents have a prior right to choose the kind of education that shall be given to their children. \n",
      "Article 27 \n",
      "Everyone has the right freely to participate in the cultural life of the community, to enjoy the arts and to share in scientific advancement and its benefits. \n",
      "Everyone has the right to the protection of the moral and material interests resulting from any scientific, literary or artistic production of which he is the author. \n",
      "Article 28 \n",
      "Everyone is entitled to a social and international order in which the rights and freedoms set forth in this Declaration can be fully realized. \n",
      "\n",
      "Article 29 \n",
      "Everyone has duties to the community in which alone th\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import udhr\n",
    "print(udhr.raw('English-Latin1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets import some sample and training text - George Bush's 2005 and 2006 state of the union addresses. \n",
    "\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have some text, we can train the PunktSentenceTokenizer\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets tokenize the sample_text using our trained tokenizer\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
      "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# This function will tag each tokenized word with a part of speech\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "        \n",
    "# The output is a list of tuples - the word with it's part of speech\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n+ = match 1 or more\\n? = match 0 or 1 repetitions.\\n* = match 0 or MORE repetitions\\t  \\n. = Any character except a new line\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "+ = match 1 or more\n",
    "? = match 0 or 1 repetitions.\n",
    "* = match 0 or MORE repetitions\t  \n",
    ". = Any character except a new line\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "(Chunk ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk THE/NNP UNION/NNP January/NNP)\n",
      "(Chunk THE/NNP PRESIDENT/NNP)\n",
      "(Chunk Thank/NNP)\n",
      "(Chunk Mr./NNP Speaker/NNP)\n",
      "(Chunk Vice/NNP President/NNP Cheney/NNP)\n",
      "(Chunk Congress/NNP)\n",
      "(Chunk Supreme/NNP Court/NNP)\n",
      "(Chunk called/VBD America/NNP)\n",
      "(Chunk Coretta/NNP Scott/NNP King/NNP)\n",
      "(Chunk Applause/NNP)\n",
      "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
      "(Chunk State/NNP)\n",
      "(Chunk Union/NNP Address/NNP)\n",
      "(Chunk Capitol/NNP)\n",
      "(Chunk Tuesday/NNP)\n",
      "(Chunk Jan/NNP)\n",
      "(Chunk White/NNP House/NNP photo/NN)\n",
      "(Chunk Eric/NNP DraperEvery/NNP time/NN)\n",
      "(Chunk Capitol/NNP dome/NN)\n",
      "(Chunk have/VBP served/VBN America/NNP)\n",
      "(Chunk Tonight/NNP)\n",
      "(Chunk Union/NNP)\n",
      "(Chunk Applause/NNP)\n",
      "(Chunk United/NNP)\n",
      "(Chunk America/NNP)\n",
      "(Chunk Applause/NNP)\n"
     ]
    }
   ],
   "source": [
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:20]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            # combine the part-of-speech tag with a regular expression\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            # print(chunked)\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                print(subtree)\n",
    "            \n",
    "            # draw the chunks with nltk\n",
    "            # chunked.draw()     \n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP 'S/POS ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk\n",
      "  THE/NNP\n",
      "  UNION/NNP\n",
      "  January/NNP\n",
      "  31/CD\n",
      "  ,/,\n",
      "  2006/CD\n",
      "  THE/NNP\n",
      "  PRESIDENT/NNP\n",
      "  :/:\n",
      "  Thank/NNP\n",
      "  you/PRP)\n",
      "(Chunk ./.)\n",
      "(Chunk\n",
      "  Mr./NNP\n",
      "  Speaker/NNP\n",
      "  ,/,\n",
      "  Vice/NNP\n",
      "  President/NNP\n",
      "  Cheney/NNP\n",
      "  ,/,\n",
      "  members/NNS)\n",
      "(Chunk Congress/NNP ,/, members/NNS)\n",
      "(Chunk\n",
      "  Supreme/NNP\n",
      "  Court/NNP\n",
      "  and/CC\n",
      "  diplomatic/JJ\n",
      "  corps/NN\n",
      "  ,/,\n",
      "  distinguished/JJ\n",
      "  guests/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  fellow/JJ\n",
      "  citizens/NNS\n",
      "  :/:)\n",
      "(Chunk our/PRP$ nation/NN)\n",
      "(Chunk ,/, graceful/JJ ,/, courageous/JJ woman/NN who/WP)\n",
      "(Chunk America/NNP)\n",
      "(Chunk its/PRP$ founding/NN ideals/NNS and/CC)\n",
      "(Chunk noble/JJ dream/NN ./.)\n",
      "(Chunk Tonight/NN we/PRP)\n",
      "(Chunk hope/NN)\n",
      "(Chunk glad/JJ reunion/NN)\n",
      "(Chunk husband/NN who/WP)\n",
      "(Chunk so/RB long/RB ago/RB ,/, and/CC we/PRP)\n",
      "(Chunk grateful/JJ)\n",
      "(Chunk good/JJ life/NN)\n",
      "(Chunk Coretta/NNP Scott/NNP King/NNP ./.)\n",
      "(Chunk (/( Applause/NNP ./. )/))\n",
      "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
      "(Chunk his/PRP$ State/NNP)\n",
      "(Chunk Union/NNP Address/NNP)\n",
      "(Chunk Capitol/NNP ,/, Tuesday/NNP ,/, Jan/NNP ./.)\n",
      "(Chunk 31/CD ,/, 2006/CD ./.)\n",
      "(Chunk White/NNP House/NNP photo/NN)\n",
      "(Chunk Eric/NNP DraperEvery/NNP time/NN I/PRP)\n",
      "(Chunk invited/JJ)\n",
      "(Chunk rostrum/NN ,/, I/PRP)\n",
      "(Chunk privilege/NN ,/, and/CC mindful/NN)\n",
      "(Chunk history/NN we/PRP)\n",
      "(Chunk together/RB ./.)\n",
      "(Chunk We/PRP)\n",
      "(Chunk Capitol/NNP dome/NN)\n",
      "(Chunk moments/NNS)\n",
      "(Chunk national/JJ mourning/NN and/CC national/JJ achievement/NN ./.)\n",
      "(Chunk We/PRP)\n",
      "(Chunk America/NNP)\n",
      "(Chunk one/CD)\n",
      "(Chunk most/RBS consequential/JJ periods/NNS)\n",
      "(Chunk our/PRP$ history/NN --/: and/CC it/PRP)\n",
      "(Chunk my/PRP$ honor/NN)\n",
      "(Chunk you/PRP ./.)\n",
      "(Chunk system/NN)\n",
      "(Chunk\n",
      "  two/CD\n",
      "  parties/NNS\n",
      "  ,/,\n",
      "  two/CD\n",
      "  chambers/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  two/CD\n",
      "  elected/JJ\n",
      "  branches/NNS\n",
      "  ,/,\n",
      "  there/EX\n",
      "  will/MD\n",
      "  always/RB)\n",
      "(Chunk differences/NNS and/CC debate/NN ./.)\n",
      "(Chunk But/CC even/RB tough/JJ debates/NNS can/MD)\n",
      "(Chunk\n",
      "  civil/JJ\n",
      "  tone/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  our/PRP$\n",
      "  differences/NNS\n",
      "  can/MD\n",
      "  not/RB)\n",
      "(Chunk anger/NN ./.)\n",
      "(Chunk great/JJ issues/NNS)\n",
      "(Chunk us/PRP ,/, we/PRP must/MD)\n",
      "(Chunk spirit/NN)\n",
      "(Chunk goodwill/NN and/CC respect/NN)\n",
      "(Chunk one/CD)\n",
      "(Chunk --/: and/CC I/PRP will/MD)\n",
      "(Chunk my/PRP$ part/NN ./.)\n",
      "(Chunk Tonight/NNP)\n",
      "(Chunk state/NN)\n",
      "(Chunk our/PRP$ Union/NNP)\n",
      "(Chunk strong/JJ --/: and/CC together/RB we/PRP will/MD)\n",
      "(Chunk it/PRP stronger/JJR ./.)\n",
      "(Chunk (/( Applause/NNP ./. )/))\n",
      "(Chunk decisive/JJ year/NN ,/, you/PRP and/CC I/PRP will/MD)\n",
      "(Chunk choices/NNS that/WDT)\n",
      "(Chunk future/NN and/CC)\n",
      "(Chunk character/NN)\n",
      "(Chunk our/PRP$ country/NN ./.)\n",
      "(Chunk We/PRP will/MD)\n",
      "(Chunk confidently/RB)\n",
      "(Chunk enemies/NNS)\n",
      "(Chunk freedom/NN --/: or/CC retreat/NN)\n",
      "(Chunk our/PRP$ duties/NNS)\n",
      "(Chunk hope/NN)\n",
      "(Chunk easier/JJR life/NN ./.)\n",
      "(Chunk We/PRP will/MD)\n",
      "(Chunk our/PRP$ prosperity/NN)\n",
      "(Chunk world/NN economy/NN --/: or/CC)\n",
      "(Chunk ourselves/PRP off/RP)\n",
      "(Chunk trade/NN and/CC opportunity/NN ./.)\n",
      "(Chunk complex/JJ and/CC challenging/JJ time/NN ,/,)\n",
      "(Chunk road/NN)\n",
      "(Chunk isolationism/NN and/CC protectionism/NN may/MD)\n",
      "(Chunk broad/JJ and/CC inviting/NN --/: yet/CC it/PRP)\n",
      "(Chunk danger/NN and/CC decline/NN ./.)\n",
      "(Chunk only/JJ way/NN)\n",
      "(Chunk our/PRP$ people/NNS ,/,)\n",
      "(Chunk only/JJ way/NN)\n",
      "(Chunk peace/NN ,/,)\n",
      "(Chunk only/JJ way/NN)\n",
      "(Chunk our/PRP$ destiny/NN)\n",
      "(Chunk our/PRP$ leadership/NN --/:)\n",
      "(Chunk United/NNP States/NNPS)\n",
      "(Chunk America/NNP will/MD)\n",
      "(Chunk ./.)\n",
      "(Chunk (/( Applause/NNP ./. )/))\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:20]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            # The main difference here is the }{, vs. the {}. This means we're removing \n",
    "            # from the chink one or more verbs, prepositions, determiners, or the word 'to'.\n",
    "\n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            # print(chunked)\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                print(subtree)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 2000\n",
      "First Review: (['note', 'to', 'screenwriters', 'and', 'self', ':', 'when', 'you', 'hit', 'the', 'big', 'time', ',', 'and', 'the', 'studios', 'come', 'knocking', 'for', 'those', 'scripts', 'that', 'are', 'sitting', 'in', 'your', 'bottom', 'drawer', ',', 'tell', '?', 'em', 'all', 'to', 'hit', 'the', 'road', '.', 'gilligan', 'wrote', 'the', 'arbitrarily', '-', 'titled', 'home', 'fries', 'ten', 'years', 'ago', ';', 'it', 'was', 'shelved', 'until', 'he', 'found', 'success', 'as', 'one', 'of', '\"', 'the', 'took', 'a', 'second', 'look', 'at', 'gilligan', \"'\", 's', '\"', 'comedy', '\"', '-', 'they', 'read', 'it', 'again', 'wearing', 'rose', '-', 'tinted', 'glasses', '.', 'drew', 'stars', 'as', 'sally', ',', 'a', 'dim', '(', 'but', 'sweet', ')', ',', 'pregnant', 'waitress', 'at', 'a', 'small', 'town', 'burger', 'joint', 'located', 'somewhere', 'in', 'the', 'southern', 'united', 'states', '.', 'the', 'father', 'of', 'her', 'child', 'is', 'dead', ',', 'the', 'victim', 'of', 'a', 'severe', 'heart', 'attack', 'brought', 'on', 'by', 'sadistic', 'torture', 'from', 'his', 'two', 'stepsons', '-', 'these', 'flyboys', 'scared', 'him', 'with', 'their', 'low', '-', 'flying', 'helicopter', '.', 'dorian', '(', 'wilson', ')', 'and', 'angus', '(', 'busey', ')', 'were', 'getting', 'even', 'for', 'his', 'philandering', 'ways', 'on', 'behalf', 'of', 'their', 'anguished', 'mother', '(', 'o', \"'\", 'hara', ')', '.', 'trouble', 'is', ',', 'sally', 'picked', 'up', 'some', 'interference', 'on', 'her', 'drive', '-', 'thru', 'headset', ',', 'and', 'angus', 'worries', 'she', 'may', 'have', 'heard', 'conversations', 'that', 'took', 'place', 'in', 'the', 'helicopter', 'prior', 'to', 'the', 'accidental', 'killing', '.', 'so', 'dorian', 'goes', 'undercover', 'as', 'a', 'burger', '-', 'flipper', ';', 'before', 'you', 'can', 'say', '\"', 'with', 'cheese', '\"', 'he', 'falls', 'for', 'the', 'mother', '-', 'to', '-', 'be', '.', 'too', 'bad', 'mom', 'and', 'angus', 'have', 'homicidal', 'plans', 'for', 'sally', '.', 'does', 'this', 'sound', 'like', 'a', 'movie', 'you', 'want', 'to', 'see', '?', 'without', 'a', 'doubt', ',', 'the', 'best', 'thing', 'about', 'home', 'fries', 'is', 'barrymore', ';', 'at', 'the', 'risk', 'of', 'sounding', 'sexist', ',', 'she', \"'\", 's', 'never', 'looked', 'better', 'than', 'here', ',', 'as', 'a', 'curly', 'redhead', 'with', 'twinkling', 'eyes', '.', 'she', 'is', 'winning', 'in', 'a', 'role', 'that', 'requires', 'her', 'to', 'do', 'absolutely', 'nothing', 'except', 'look', 'apple', '-', 'cheek', 'cute', 'and', 'gawk', 'at', 'wilson', ',', 'her', 'real', '-', 'life', 'boyfriend', '.', 'but', 'the', 'plot', 'and', 'the', 'situations', 'are', 'so', 'off', '-', 'putting', 'that', 'nothing', 'could', 'save', 'it', '.', 'this', 'movie', 'desperately', 'wants', 'to', 'get', 'mentioned', 'in', 'the', 'same', 'breath', 'as', 'the', 'coen', 'brothers', ',', 'but', 'home', 'fries', \"'\", 'brand', 'of', 'laboured', 'hipness', 'would', 'be', 'foreign', 'to', 'geniuses', 'like', 'ethan', 'and', 'joel', '.', 'it', \"'\", 's', 'raising', 'arizona', 'without', 'babies', ',', 'without', 'charm', ',', 'without', 'laughs', ',', 'without', 'human', 'characters', ',', 'and', 'without', 'intelligence', ';', 'worst', 'of', 'all', ',', 'it', \"'\", 's', 'creepy', '.', 'what', \"'\", 's', 'funny', 'about', 'threatening', 'to', 'gun', 'down', 'a', 'pregnant', 'woman', 'with', 'a', 'machine', 'gun', '?', '(', 'unless', 'the', 'woman', 'in', 'question', 'is', 'a', 'spice', 'girl', '.', ')', 'take', 'out', 'the', 'helicopters', ',', 'the', 'quasi', '-', 'incestuous', 'relationship', 'between', 'the', 'mother', 'and', 'her', 'sons', '(', 'it', 'is', 'absolutely', 'illogical', ',', 'within', 'the', 'movie', \"'\", 's', 'framework', ',', 'that', 'dorian', 'still', 'lives', 'with', 'his', 'mother', 'and', 'brother', ')', ',', 'and', 'the', 'scenes', 'of', 'murder', '(', 'attempted', 'and', 'otherwise', ')', ',', 'and', 'what', 'are', 'you', 'left', 'with', '?', 'the', 'story', 'of', 'a', 'single', 'woman', 'with', 'child', 'who', 'works', 'at', 'a', 'fast', 'food', 'joint', '(', 'but', 'dreams', 'of', 'becoming', 'a', 'country', 'singer', ')', '.', 'that', 'could', 'turn', 'out', 'to', 'be', 'the', 'most', 'boring', 'movie', 'ever', 'made', ',', 'but', 'it', \"'\", 'd', 'be', 'better', 'than', 'home', 'fries', '.'], 'neg')\n",
      "Most common words: [(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "The word happy: 215\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# shuffle the documents\n",
    "random.shuffle(documents)\n",
    "\n",
    "print('Number of Documents: {}'.format(len(documents)))\n",
    "print('First Review: {}'.format(documents[1]))\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))\n",
    "print('The word happy: {}'.format(all_words[\"happy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39768\n"
     ]
    }
   ],
   "source": [
    "# We'll use the 4000 most common words as features\n",
    "print(len(all_words))\n",
    "word_features = list(all_words.keys())[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot\n",
      ":\n",
      "two\n",
      "teen\n",
      "couples\n",
      "go\n",
      "to\n",
      "a\n",
      "church\n",
      "party\n",
      ",\n",
      "drink\n",
      "and\n",
      "then\n",
      "drive\n",
      ".\n",
      "they\n",
      "get\n",
      "into\n",
      "an\n",
      "accident\n",
      "one\n",
      "of\n",
      "the\n",
      "guys\n",
      "dies\n",
      "but\n",
      "his\n",
      "girlfriend\n",
      "continues\n",
      "see\n",
      "him\n",
      "in\n",
      "her\n",
      "life\n",
      "has\n",
      "nightmares\n",
      "what\n",
      "'\n",
      "s\n",
      "deal\n",
      "?\n",
      "watch\n",
      "movie\n",
      "\"\n",
      "sorta\n",
      "find\n",
      "out\n",
      "critique\n",
      "mind\n",
      "-\n",
      "fuck\n",
      "for\n",
      "generation\n",
      "that\n",
      "touches\n",
      "on\n",
      "very\n",
      "cool\n",
      "idea\n",
      "presents\n",
      "it\n",
      "bad\n",
      "package\n",
      "which\n",
      "is\n",
      "makes\n",
      "this\n",
      "review\n",
      "even\n",
      "harder\n",
      "write\n",
      "since\n",
      "i\n",
      "generally\n",
      "applaud\n",
      "films\n",
      "attempt\n",
      "break\n",
      "mold\n",
      "mess\n",
      "with\n",
      "your\n",
      "head\n",
      "such\n",
      "(\n",
      "lost\n",
      "highway\n",
      "&\n",
      "memento\n",
      ")\n",
      "there\n",
      "are\n",
      "good\n",
      "ways\n",
      "making\n",
      "all\n",
      "types\n",
      "these\n",
      "folks\n",
      "just\n",
      "didn\n",
      "t\n",
      "snag\n",
      "correctly\n",
      "seem\n",
      "have\n",
      "taken\n",
      "pretty\n",
      "neat\n",
      "concept\n",
      "executed\n",
      "terribly\n",
      "so\n",
      "problems\n",
      "well\n",
      "its\n",
      "main\n",
      "problem\n",
      "simply\n",
      "too\n",
      "jumbled\n",
      "starts\n",
      "off\n",
      "normal\n",
      "downshifts\n",
      "fantasy\n",
      "world\n",
      "you\n",
      "as\n",
      "audience\n",
      "member\n",
      "no\n",
      "going\n",
      "dreams\n",
      "characters\n",
      "coming\n",
      "back\n",
      "from\n",
      "dead\n",
      "others\n",
      "who\n",
      "look\n",
      "like\n",
      "strange\n",
      "apparitions\n",
      "disappearances\n",
      "looooot\n",
      "chase\n",
      "scenes\n",
      "tons\n",
      "weird\n",
      "things\n",
      "happen\n",
      "most\n",
      "not\n",
      "explained\n",
      "now\n",
      "personally\n",
      "don\n",
      "trying\n",
      "unravel\n",
      "film\n",
      "every\n",
      "when\n",
      "does\n",
      "give\n",
      "me\n",
      "same\n",
      "clue\n",
      "over\n",
      "again\n",
      "kind\n",
      "fed\n",
      "up\n",
      "after\n",
      "while\n",
      "biggest\n",
      "obviously\n",
      "got\n",
      "big\n",
      "secret\n",
      "hide\n",
      "seems\n",
      "want\n",
      "completely\n",
      "until\n",
      "final\n",
      "five\n",
      "minutes\n",
      "do\n",
      "make\n",
      "entertaining\n",
      "thrilling\n",
      "or\n",
      "engaging\n",
      "meantime\n",
      "really\n",
      "sad\n",
      "part\n",
      "arrow\n",
      "both\n",
      "dig\n",
      "flicks\n",
      "we\n",
      "actually\n",
      "figured\n",
      "by\n",
      "half\n",
      "way\n",
      "point\n",
      "strangeness\n",
      "did\n",
      "start\n",
      "little\n",
      "bit\n",
      "sense\n",
      "still\n",
      "more\n",
      "guess\n",
      "bottom\n",
      "line\n",
      "movies\n",
      "should\n",
      "always\n",
      "sure\n",
      "before\n",
      "given\n",
      "password\n",
      "enter\n",
      "understanding\n",
      "mean\n",
      "showing\n",
      "melissa\n",
      "sagemiller\n",
      "running\n",
      "away\n",
      "visions\n",
      "about\n",
      "20\n",
      "throughout\n",
      "plain\n",
      "lazy\n",
      "!\n",
      "okay\n",
      "people\n",
      "chasing\n",
      "know\n",
      "need\n",
      "how\n",
      "giving\n",
      "us\n",
      "different\n",
      "offering\n",
      "further\n",
      "insight\n",
      "down\n",
      "apparently\n",
      "studio\n",
      "took\n",
      "director\n",
      "chopped\n",
      "themselves\n",
      "shows\n",
      "might\n",
      "ve\n",
      "been\n",
      "decent\n",
      "here\n",
      "somewhere\n",
      "suits\n",
      "decided\n",
      "turning\n",
      "music\n",
      "video\n",
      "edge\n",
      "would\n",
      "actors\n",
      "although\n",
      "wes\n",
      "bentley\n",
      "seemed\n",
      "be\n",
      "playing\n",
      "exact\n",
      "character\n",
      "he\n",
      "american\n",
      "beauty\n",
      "only\n",
      "new\n",
      "neighborhood\n",
      "my\n",
      "kudos\n",
      "holds\n",
      "own\n",
      "entire\n",
      "feeling\n",
      "unraveling\n",
      "overall\n",
      "doesn\n",
      "stick\n",
      "because\n",
      "entertain\n",
      "confusing\n",
      "rarely\n",
      "excites\n",
      "feels\n",
      "redundant\n",
      "runtime\n",
      "despite\n",
      "ending\n",
      "explanation\n",
      "craziness\n",
      "came\n",
      "oh\n",
      "horror\n",
      "slasher\n",
      "flick\n",
      "packaged\n",
      "someone\n",
      "assuming\n",
      "genre\n",
      "hot\n",
      "kids\n",
      "also\n",
      "wrapped\n",
      "production\n",
      "years\n",
      "ago\n",
      "sitting\n",
      "shelves\n",
      "ever\n",
      "whatever\n",
      "skip\n",
      "where\n",
      "joblo\n",
      "nightmare\n",
      "elm\n",
      "street\n",
      "3\n",
      "7\n",
      "/\n",
      "10\n",
      "blair\n",
      "witch\n",
      "2\n",
      "crow\n",
      "9\n",
      "salvation\n",
      "4\n",
      "stir\n",
      "echoes\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# The find_features function will determine which of the 4000 word features are contained in the review\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# Lets use an example from a negative review\n",
    "features = find_features(movie_reviews.words('neg/cv000_29416.txt'))\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can split the featuresets into training and testing datasets using sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "# define a seed for reproducibility\n",
    "seed = 1\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 78.8%\n"
     ]
    }
   ],
   "source": [
    "# We can use sklearn algorithms in NLTK\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
